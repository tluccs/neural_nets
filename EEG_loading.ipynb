{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 239 Final Project\n",
    "\n",
    "In this project we explore various deep learning algorithms on the EEG dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "\n",
    "from utils.load_data import *\n",
    "from models.cnn import CNN\n",
    "from models.rnn import RNN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loads data from the EEG dataset and removes all EOG data\n",
    "\n",
    "person_train_valid, X_train_valid, y_train_valid, person_test, X_test, y_test = load_EEG_data()\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1904, 22, 1000)\n",
      "Training target shape: (1904,)\n",
      "Validation data shape: (211, 22, 1000)\n",
      "Validation target shape: (211,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = split_train_val(X_train_valid, y_train_valid, percent_validation=0.1)\n",
    "\n",
    "print ('Training data shape: {}'.format(X_train.shape))\n",
    "print ('Training target shape: {}'.format(y_train.shape))\n",
    "print ('Validation data shape: {}'.format(X_val.shape))\n",
    "print ('Validation target shape: {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding for all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n",
      "(211,)\n",
      "(443,)\n",
      "[1. 0. 0. 0.]\n",
      "(211, 4)\n",
      "(443, 4)\n"
     ]
    }
   ],
   "source": [
    "print (y_val[33])\n",
    "print (y_val.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "def convert_to_label(num):\n",
    "    return np.array([1.0*(num==769),  1.0*(num==770), 1.0*(num==771), 1.0*(num==772)])\n",
    "\n",
    "y_train_labels = np.array([convert_to_label(yi) for yi in y_train])\n",
    "y_val_labels = np.array([convert_to_label(yi) for yi in y_val])\n",
    "y_test_labels = np.array([convert_to_label(yi) for yi in y_test])\n",
    "\n",
    "print (y_val_labels[33])\n",
    "print (y_val_labels.shape)\n",
    "print (y_test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying data using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jayantmehra/Documents/CS239AS/Project/neural_nets/venv/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 1904 samples, validate on 211 samples\n",
      "WARNING:tensorflow:From /Users/jayantmehra/Documents/CS239AS/Project/neural_nets/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1904/1904 [==============================] - 1s 413us/sample - loss: 1.4217 - acc: 0.2358 - val_loss: 1.3888 - val_acc: 0.2701\n",
      "Epoch 2/5\n",
      "1904/1904 [==============================] - 0s 242us/sample - loss: 1.3681 - acc: 0.3178 - val_loss: 1.4282 - val_acc: 0.2322\n",
      "Epoch 3/5\n",
      "1904/1904 [==============================] - 0s 237us/sample - loss: 1.3260 - acc: 0.3634 - val_loss: 1.4486 - val_acc: 0.2464\n",
      "Epoch 4/5\n",
      "1904/1904 [==============================] - 0s 236us/sample - loss: 1.2791 - acc: 0.3997 - val_loss: 1.4998 - val_acc: 0.2512\n",
      "Epoch 5/5\n",
      "1904/1904 [==============================] - 0s 223us/sample - loss: 1.2202 - acc: 0.4270 - val_loss: 1.4862 - val_acc: 0.2464\n",
      "443/443 [==============================] - 0s 124us/sample - loss: 1.4268 - acc: 0.3160\n",
      "Test loss: 1.4267922473007615\n",
      "Test accuracy: 0.31602708\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(X_train, y_train_labels, X_val, y_val_labels, X_test, y_test_labels)\n",
    "cnn.train(stride=2, optimizer='adam', epochs=5)\n",
    "test_loss, test_accuracy = cnn.evaluate()\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifying data using an LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jayantmehra/Documents/CS239AS/Project/neural_nets/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 1904 samples, validate on 211 samples\n",
      "Epoch 1/5\n",
      "1904/1904 [==============================] - 6s 3ms/step - loss: 0.6275 - acc: 0.6719 - val_loss: 0.5944 - val_acc: 0.7216\n",
      "Epoch 2/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.4454 - acc: 0.8058 - val_loss: 0.5919 - val_acc: 0.7239\n",
      "Epoch 3/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.3527 - acc: 0.8785 - val_loss: 0.5901 - val_acc: 0.7192\n",
      "Epoch 4/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.2815 - acc: 0.9246 - val_loss: 0.6043 - val_acc: 0.7204\n",
      "Epoch 5/5\n",
      "1904/1904 [==============================] - 5s 3ms/step - loss: 0.2228 - acc: 0.9596 - val_loss: 0.5989 - val_acc: 0.7227\n",
      "Test loss: 0.6121573761677366\n",
      "Test accuracy: 0.7200902941264633\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(X_train, y_train_labels, X_val, y_val_labels, X_test, y_test_labels)\n",
    "rnn.train(RNN_architecture=LSTM, activation=\"sigmoid\", \\\n",
    "              optimizer='adam', epochs=5, batch_size=64, dropout=0.1)\n",
    "test_loss, test_accuracy = rnn.evaluate()\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data using a GRU Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1904 samples, validate on 211 samples\n",
      "Epoch 1/5\n",
      "1904/1904 [==============================] - 5s 2ms/step - loss: 0.6889 - acc: 0.6624 - val_loss: 0.6464 - val_acc: 0.6919\n",
      "Epoch 2/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.4274 - acc: 0.8167 - val_loss: 0.6387 - val_acc: 0.7062\n",
      "Epoch 3/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.3080 - acc: 0.8964 - val_loss: 0.6367 - val_acc: 0.7097\n",
      "Epoch 4/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.2266 - acc: 0.9442 - val_loss: 0.6463 - val_acc: 0.7026\n",
      "Epoch 5/5\n",
      "1904/1904 [==============================] - 4s 2ms/step - loss: 0.1708 - acc: 0.9730 - val_loss: 0.6702 - val_acc: 0.7097\n",
      "Test loss: 0.6635286232149628\n",
      "Test accuracy: 0.6963882631964932\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(X_train, y_train_labels, X_val, y_val_labels, X_test, y_test_labels)\n",
    "rnn.train(RNN_architecture=GRU, activation=\"sigmoid\", \\\n",
    "              optimizer='adam', epochs=5, batch_size=64, dropout=0.1)\n",
    "test_loss, test_accuracy = rnn.evaluate()\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
