{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 239 Final Project\n",
    "\n",
    "In this project we explore various deep learning algorithms on the EEG dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils.load_data import *\n",
    "from models.cnn import CNN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loads data from the EEG dataset and removes all EOG data\n",
    "\n",
    "person_train_valid, X_train_valid, y_train_valid, person_test, X_test, y_test = load_EEG_data()\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1904, 22, 1000)\n",
      "Training target shape: (1904,)\n",
      "Validation data shape: (211, 22, 1000)\n",
      "Validation target shape: (211,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = split_train_val(X_train_valid, y_train_valid, percent_validation=0.1)\n",
    "\n",
    "print ('Training data shape: {}'.format(X_train.shape))\n",
    "print ('Training target shape: {}'.format(y_train.shape))\n",
    "print ('Validation data shape: {}'.format(X_val.shape))\n",
    "print ('Validation target shape: {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding for all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "(211,)\n",
      "(443,)\n",
      "[0. 0. 1. 0.]\n",
      "(211, 4)\n",
      "(443, 4)\n"
     ]
    }
   ],
   "source": [
    "print (y_val[33])\n",
    "print (y_val.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "def convert_to_label(num):\n",
    "    return np.array([1.0*(num==769),  1.0*(num==770), 1.0*(num==771), 1.0*(num==772)])\n",
    "\n",
    "y_train_labels = np.array([convert_to_label(yi) for yi in y_train])\n",
    "y_val_labels = np.array([convert_to_label(yi) for yi in y_val])\n",
    "y_test_labels = np.array([convert_to_label(yi) for yi in y_test])\n",
    "\n",
    "print (y_val_labels[33])\n",
    "print (y_val_labels.shape)\n",
    "print (y_test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying data using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1904 samples, validate on 211 samples\n",
      "Epoch 1/5\n",
      "1904/1904 [==============================] - 1s 428us/sample - loss: 1.4199 - acc: 0.2773 - val_loss: 1.4022 - val_acc: 0.2701\n",
      "Epoch 2/5\n",
      "1904/1904 [==============================] - 0s 205us/sample - loss: 1.3731 - acc: 0.3151 - val_loss: 1.4088 - val_acc: 0.3175\n",
      "Epoch 3/5\n",
      "1904/1904 [==============================] - 0s 230us/sample - loss: 1.3402 - acc: 0.3414 - val_loss: 1.4041 - val_acc: 0.2938\n",
      "Epoch 4/5\n",
      "1904/1904 [==============================] - 0s 197us/sample - loss: 1.3122 - acc: 0.3682 - val_loss: 1.3918 - val_acc: 0.2938\n",
      "Epoch 5/5\n",
      "1904/1904 [==============================] - 0s 209us/sample - loss: 1.2826 - acc: 0.3929 - val_loss: 1.4081 - val_acc: 0.3318\n",
      "443/443 [==============================] - 0s 106us/sample - loss: 1.4507 - acc: 0.2867\n",
      "Test loss: 1.450662408940679\n",
      "Test accuracy: 0.2866817\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(X_train, y_train_labels, X_val, y_val_labels, X_test, y_test_labels)\n",
    "cnn.train(stride=2, optimizer='adam', epochs=5)\n",
    "test_loss, test_accuracy = cnn.evaluate()\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
